# üó∫Ô∏è OLIST DATA PLATFORM - ROADMAP COMPLETO

**Dura√ß√£o Total:** 8 semanas | **Esfor√ßo:** 120-160 horas | **Complexidade:** Pleno

---

## üìä VIS√ÉO GERAL DO PROJETO

### **Objetivo**
Construir plataforma de dados end-to-end demonstrando pr√°ticas enterprise em engenharia de dados, analytics, MLOps e BI.

### **Entregas Finais**
- 8 DAGs Airflow produ√ß√£o
- 20+ modelos DBT (bronze/silver/gold)
- 15+ valida√ß√µes Great Expectations
- 1 modelo ML com MLflow
- 4 dashboards (Power BI + Metabase)
- IA analytics com Vertex AI Gemini
- Documenta√ß√£o completa (10+ p√°ginas)

### **Skills Demonstradas**
Data Engineering (40%) | Analytics Engineering (30%) | MLOps (15%) | BI (10%) | AI (5%)

---

üü´ FASE 1 ‚Äî INGEST√ÉO (BRONZE)
Objetivo

Garantir dados brutos confi√°veis, audit√°veis e reprocess√°veis.

Entram nesta fase:

ingest√£o (CSV / API / DB)

orquestra√ß√£o com Airflow

idempot√™ncia

ordena√ß√£o de carga

persist√™ncia no Data Lake

data quality estrutural

documenta√ß√£o t√©cnica base

Data Quality (aqui √© estrutural)

schema existe

colunas obrigat√≥rias

tipos compat√≠veis

PK/FK v√°lidas

volumetria dentro do esperado

üìå N√£o entra:

regra de neg√≥cio

limpeza sem√¢ntica

transforma√ß√£o anal√≠tica

‚úîÔ∏è Bronze = fidelidade ao dado original.

üü¶ FASE 2 ‚Äî SILVER + QUALIDADE + OBSERVABILIDADE + DRIFT

üëâ Essa √© a fase mais importante do seu projeto do ponto de vista de maturidade.

Objetivo

Transformar dados brutos em dados est√°veis, padronizados e confi√°veis ao longo do tempo.

üîπ Limpeza e Padroniza√ß√£o (Silver)

normaliza√ß√£o de campos

padroniza√ß√£o de tipos

tratamento expl√≠cito de nulos

deduplica√ß√£o com regra clara

chaves substitutas quando necess√°rio

üîπ Data Quality (n√≠vel sem√¢ntico)

Great Expectations como contrato

valida√ß√µes de:

unicidade l√≥gica

consist√™ncia p√≥s-join

ranges realistas

nullability consciente

üìå Aqui qualidade n√£o √© s√≥ ‚Äúpassou ou falhou‚Äù, √© controle de expectativa.

üîπ Schema Drift & Evolution (entra AQUI)

Corret√≠ssimo voc√™ colocar na Silver.

snapshot de schema

compara√ß√£o entre vers√µes

classifica√ß√£o de mudan√ßa

hist√≥rico de evolu√ß√£o

alerta autom√°tico

üìå Silver √© onde o drift deve ser detectado e controlado, n√£o ignorado.

üîπ Observabilidade (entra AQUI)

m√©tricas de qualidade

hist√≥rico de falhas

row counts

logs estruturados

dashboard t√©cnico (Streamlit)

üìå Observabilidade ‚â† BI
Observabilidade √© para engenharia, n√£o para neg√≥cio.

üîπ Documenta√ß√£o Executiva

Data Docs (GE)

decis√µes arquiteturais

trade-offs

limita√ß√µes conhecidas

üëâ Essa documenta√ß√£o nasce na Silver, porque aqui o dado ‚Äúganha forma‚Äù.

üü® FASE 3 ‚Äî GOLD + DBT + BI + PROBLEMA DE NEG√ìCIO
Objetivo

Transformar dados confi√°veis em informa√ß√£o acion√°vel.

üîπ dbt (entra oficialmente AQUI)

modelagem dimensional

fatos e dimens√µes

testes autom√°ticos

versionamento

lineage

documenta√ß√£o viva

üìå dbt faz sentido quando:

schema √© est√°vel

dados j√° foram limpos

drift est√° controlado

üëâ Sua decis√£o de deixar dbt para a Gold √© excelente.

üîπ Gold Layer

dados orientados a consumo

modelos espec√≠ficos:

BI

Analytics

sem ambiguidade

sem l√≥gica escondida

üîπ BI / Dashboard

KPIs claros

m√©tricas de neg√≥cio

visualiza√ß√£o

storytelling de dados

üìå Aqui nasce o problema de neg√≥cio:

gargalo

inefici√™ncia

oportunidade

üîπ Documenta√ß√£o Anal√≠tica

defini√ß√£o de m√©tricas

significado dos KPIs

p√∫blico-alvo

üü• FASE 4 ‚Äî ML + MLOps (ORIENTADO AO PROBLEMA)
Objetivo

Resolver um problema real, j√° identificado.

üîπ ML

feature engineering a partir da Gold

modelo simples e explic√°vel

m√©tricas alinhadas ao problema

baseline claro

üîπ MLOps

versionamento de dados e modelo

reprodutibilidade

pipeline de treino

monitoramento b√°sico

üìå ML aqui n√£o √© vitrine, √© consequ√™ncia l√≥gica.

3Ô∏è‚É£ Onde cada feature ficou (resumo r√°pido)
Feature	Fase
Ingest√£o	Fase 1
Airflow	Fase 1 ‚Üí 4
Data Lake	Fase 1
Data Quality (estrutura)	Fase 1
Data Quality (sem√¢ntica)	Fase 2
Great Expectations Docs	Fase 2
Schema Drift	Fase 2
Observabilidade t√©cnica	Fase 2
Streamlit (engenharia)	Fase 2
dbt	Fase 3
Gold models	Fase 3
BI / Analytics	Fase 3
Problema de neg√≥cio	Fase 3
ML	Fase 4
MLOps	Fase 4

---

## üß† FASE 6: AI-POWERED MONITORING

**Dura√ß√£o:** 2 dias | **Esfor√ßo:** 6-8h

### **Objetivos**
- Vertex AI Gemini integrado
- Diagn√≥stico autom√°tico de falhas
- Alertas inteligentes

### **Tarefas**

#### **Dia 39: Vertex AI Setup (3h)**
- [ ] Ativar Vertex AI API no GCP
- [ ] Criar `src/ai_analytics/gemini_client.py`
- [ ] Fun√ß√£o: `analyze_logs(dag_id, task_id, error_message)`
- [ ] Prompt estruturado:
```
Voc√™ √© especialista em Airflow.
DAG: {dag_id}
Task: {task_id}
Erro: {error_message}
Logs: {logs_ultimas_100_linhas}
Analise e retorne JSON:
{
  "causa_raiz": "...",
  "sugestao_correcao": "...",
  "severidade": "critical/high/medium/low"
}
```
- [ ] Testar com erro simulado

#### **Dia 40: Integra√ß√£o Airflow (3h)**
- [ ] Modificar DAGs para capturar falhas
- [ ] On failure callback: chamar Gemini
- [ ] Parse resposta JSON
- [ ] Enviar alerta Telegram com diagn√≥stico
- [ ] Criar ticket GitHub (opcional)

**Exemplo Alerta:**
```
‚ö†Ô∏è DAG `dbt_run` FAILED
Task: `dbt_silver_models`

ü§ñ Diagn√≥stico IA:
Erro de sintaxe SQL no modelo `int_order_metrics.sql`
Linha 15: coluna `oder_id` n√£o existe (typo: order_id)

üí° Corre√ß√£o sugerida:
Alterar `oder_id` ‚Üí `order_id` linha 15

üîó Logs: [link]
```

### **Entreg√°veis Fase 6**
- [x] Vertex AI Gemini configurado
- [x] Diagn√≥stico autom√°tico funcionando
- [x] Alertas Telegram com IA
- [x] 3+ tipos de erro testados
- [x] Documenta√ß√£o: `docs/PHASE_6_AI_ANALYTICS.md`

---

## üìö FASE 7: DOCUMENTA√á√ÉO & POLISH

**Dura√ß√£o:** 1 dia | **Esfor√ßo:** 8-10h

### **Objetivos**
- README profissional
- Documenta√ß√£o completa (7 fases)
- Diagramas de arquitetura
- V√≠deo demo
- LinkedIn post

### **Tarefas**

#### **Dia 41: Documenta√ß√£o (6h)**
- [ ] Atualizar `README.md` (3000+ palavras)
- [ ] Criar/revisar 7 arquivos `PHASE_*.md`
- [ ] Criar `docs/ARCHITECTURE.md`
- [ ] Diagramas (draw.io ou Excalidraw):
  - [ ] Arquitetura geral
  - [ ] Pipeline de dados
  - [ ] Fluxo MLOps
- [ ] Adicionar badges no README
- [ ] Screenshots de dashboards
- [ ] GIFs de execu√ß√µes Airflow

#### **Dia 41 (tarde): V√≠deo e LinkedIn (4h)**
- [ ] Gravar v√≠deo demo (5 minutos):
  - [ ] Mostrar Airflow UI
  - [ ] Executar DAG
  - [ ] Mostrar dashboard Power BI
  - [ ] Mostrar MLflow
  - [ ] Mostrar alerta Telegram
- [ ] Upload no YouTube (unlisted)
- [ ] Escrever LinkedIn post (3 vers√µes):
  - [ ] Vers√£o BI (foco dashboards)
  - [ ] Vers√£o Analytics Eng (foco DBT)
  - [ ] Vers√£o Data Platform (completo)
- [ ] Publicar e engajar

### **Entreg√°veis Fase 7**
- [x] README.md atualizado (profissional)
- [x] 7 arquivos PHASE_*.md completos
- [x] 3 diagramas de arquitetura
- [x] V√≠deo demo (5 min)
- [x] LinkedIn post publicado
- [x] Portfolio 100% completo

---

## ‚úÖ CRIT√âRIOS DE SUCESSO

### **T√©cnicos**
- [ ] 8 DAGs Airflow sem erros (7 dias uptime)
- [ ] 100% Great Expectations passing
- [ ] 20+ modelos DBT deployados
- [ ] AUC-ROC modelo ML > 0.60
- [ ] 4 dashboards publicados
- [ ] 0 secrets no Git

### **Documenta√ß√£o**
- [ ] README com 3000+ palavras
- [ ] 7 arquivos de fase (10+ p√°ginas total)
- [ ] 3 diagramas profissionais
- [ ] V√≠deo demo gravado

### **Carreira**
- [ ] GitHub: 50+ commits
- [ ] LinkedIn: post com 50+ rea√ß√µes
- [ ] Curr√≠culo: 3 vers√µes (BI, Analytics, Platform)
- [ ] Aplica√ß√µes: 10+ vagas

---

## üéØ M√âTRICAS FINAIS DO PROJETO

| M√©trica | Valor |
|---------|-------|
| **Total de Registros** | 550.118 |
| **Tabelas Relacionais** | 9 |
| **Airflow DAGs** | 8 |
| **DBT Models** | 20+ |
| **Great Expectations** | 15+ |
| **Dashboards** | 4 |
| **Modelos ML** | 1 |
| **Linhas de C√≥digo** | ~3.000 |
| **Commits Git** | 50+ |
| **P√°ginas Docs** | 10+ |

---

## üìñ RECURSOS DE APRENDIZADO

### **Durante o Projeto**
- Airflow Docs: https://airflow.apache.org/docs/
- DBT Learn: https://courses.getdbt.com/
- Great Expectations: https://docs.greatexpectations.io/
- MLflow Docs: https://mlflow.org/docs/

### **Comunidades**
- r/dataengineering (Reddit)
- DBT Slack Community
- Stack Overflow (tags: airflow, dbt, great-expectations)

---

## üÜò TROUBLESHOOTING R√ÅPIDO

**Airflow n√£o sobe:**
```bash
docker-compose down -v
docker-compose up airflow-init
docker-compose up -d
```

**DAG n√£o aparece:**
- Verificar sintaxe Python
- Checar logs: `docker-compose logs airflow-scheduler`
- Refresh: F5 no browser

**GCS upload falha:**
- Validar service account permissions
- Testar: `gsutil ls gs://seu-bucket`

**DBT connection error:**
- Validar `profiles.yml`
- Testar: `dbt debug`

---

**Status:** Ready to Execute  
**√öltima Atualiza√ß√£o:** Janeiro 2025  
**Vers√£o:** 1.0

ü§ñ PROMPT TEMPLATE PARA IAs
markdown# TEMPLATE DE PROMPT - ASSIST√äNCIA NO PROJETO OLIST DATA PLATFORM

## üìã CONTEXTO DO PROJETO

**Projeto:** Olist Data Platform  
**Objetivo:** Construir plataforma de dados end-to-end (engenharia de dados + analytics + MLOps + BI)  
**Stack:** Airflow, DBT, Great Expectations, MLflow, Power BI, Metabase, Vertex AI  
**Dataset:** Olist Brazilian E-commerce (Kaggle) - 9 tabelas, 550k registros  
**Dura√ß√£o:** 8 semanas | **Status Atual:** [PREENCHER FASE ATUAL]

---

## üéØ COMO USAR ESTE TEMPLATE

Copie o template abaixo e preencha as se√ß√µes marcadas com [PREENCHER].  
Cole no ChatGPT/Claude/Gemini para obter assist√™ncia contextual.

---

## üìù PROMPT TEMPLATE
```
Sou desenvolvedor trabalhando no projeto **Olist Data Platform**, uma plataforma de dados completa para e-commerce demonstrando pr√°ticas enterprise.

**CONTEXTO DO PROJETO:**
- Stack: Airflow (orquestra√ß√£o), DBT (transforma√ß√£o), PostgreSQL + BigQuery (storage), MLflow (ML), Power BI (BI)
- Dataset: Olist Brazilian E-commerce (9 tabelas relacionais, 550k registros)
- Ambiente: Docker (Airflow local), Google Cloud Platform (BigQuery, GCS, Vertex AI)
- Objetivo: Portfolio profissional para vagas de Data Engineer / Analytics Engineer

**FASE ATUAL:**
[PREENCHER: ex: "Fase 3 - Analytics Engineering com DBT, estou criando modelos silver layer"]

**TAREFA ESPEC√çFICA:**
[PREENCHER: ex: "Preciso criar modelo DBT que calcula SLA de entrega (data real vs estimada)"]

**O QUE J√Å FIZ:**
[PREENCHER: ex: "J√° tenho dados em PostgreSQL, schema com 9 tabelas, DBT configurado"]

**ONDE ESTOU TRAVADO:**
[PREENCHER: ex: "N√£o sei como fazer DATEDIFF no BigQuery SQL"]

**D√öVIDA/PEDIDO:**
[PREENCHER: ex: "Me ajude a escrever query SQL (BigQuery) para calcular SLA de entrega"]

**FORMATO DESEJADO DA RESPOSTA:**
[ESCOLHA UMA OU MAIS:]
- [ ] Explica√ß√£o conceitual (sem c√≥digo ainda)
- [ ] C√≥digo SQL comentado
- [ ] C√≥digo Python comentado
- [ ] Passo a passo (1, 2, 3...)
- [ ] Exemplos pr√°ticos
- [ ] Boas pr√°ticas da ind√∫stria
- [ ] Links para documenta√ß√£o oficial

**RESTRI√á√ïES:**
- Usar apenas ferramentas gratuitas/open source
- C√≥digo deve rodar no ambiente Docker/GCP free tier
- Seguir padr√µes do projeto (nomes de pastas, conven√ß√µes)

**INFORMA√á√ÉO ADICIONAL:**
[OPCIONAL: qualquer contexto extra relevante]
```

---

## üìö EXEMPLOS DE USO

### **Exemplo 1: Ajuda com DBT**
```
Sou desenvolvedor trabalhando no projeto Olist Data Platform.

**FASE ATUAL:** Fase 3 - DBT, criando modelos silver layer

**TAREFA:** Criar modelo `int_order_metrics.sql` que calcula m√©tricas de pedidos

**O QUE J√Å FIZ:**
- DBT configurado, conectado no BigQuery
- Modelo bronze `stg_orders` j√° existe
- Tabelas: orders (order_id, order_purchase_timestamp, order_delivered_customer_date, order_estimated_delivery_date)

**ONDE ESTOU TRAVADO:**
- Como calcular diferen√ßa de dias entre datas no BigQuery?
- Como criar flag booleana "atrasado" (delivered > estimated)?

**D√öVIDA:**
Me ajude a escrever modelo DBT que:
1. Calcula dias entre purchase e delivery
2. Calcula dias de atraso (0 se entregue no prazo)
3. Cria flag `is_delayed` (boolean)

**FORMATO:** C√≥digo SQL comentado (BigQuery syntax)
```

---

### **Exemplo 2: Ajuda com Airflow**
```
Projeto: Olist Data Platform

**FASE ATUAL:** Fase 1 - Ingest√£o de dados

**TAREFA:** Criar DAG Airflow para carregar CSVs no PostgreSQL

**O QUE J√Å FIZ:**
- Airflow rodando via Docker
- 9 CSVs em `data/raw/`
- PostgreSQL com schema criado (9 tabelas vazias)

**ONDE ESTOU TRAVADO:**
- Como definir ordem de execu√ß√£o? (tabelas t√™m Foreign Keys)
- Como passar path do CSV para fun√ß√£o Python?

**D√öVIDA:**
Me mostre estrutura de DAG com:
- Tasks din√¢micas (loop sobre lista de tabelas)
- Depend√™ncias corretas (FKs)
- Error handling b√°sico

**FORMATO:** C√≥digo Python comentado
```

---

### **Exemplo 3: Ajuda com ML**
```
Projeto: Olist Data Platform

**FASE ATUAL:** Fase 4 - Machine Learning

**TAREFA:** Treinar XGBoost para prever atraso de entrega

**O QUE J√Å FIZ:**
- Features prontas no BigQuery (tabela `ml_delivery_features`)
- Colunas: distancia_km, categoria_produto, metodo_pagamento, seller_rating, label (is_delayed boolean)

**ONDE ESTOU TRAVADO:**
- Como fazer split temporal (n√£o aleat√≥rio)?
- XGBoost aceita vari√°veis categ√≥ricas direto ou precisa encoding?

**D√öVIDA:**
Me mostre c√≥digo Python para:
1. Carregar dados do BigQuery
2. Split temporal (70/15/15 por data)
3. Treinar XGBoost (lidar com categ√≥ricas)
4. Calcular AUC-ROC

**FORMATO:** C√≥digo Python comentado + explica√ß√£o do split temporal
```

---

## üéì DICAS PARA PROMPTS EFICAZES

### **‚úÖ FA√áA:**
- Seja espec√≠fico sobre a fase/tarefa atual
- Mencione o que j√° funciona (para n√£o repetir)
- Indique formato desejado (c√≥digo, explica√ß√£o, passo a passo)
- Diga suas restri√ß√µes (ferramentas gratuitas, ambiente Docker)

### **‚ùå EVITE:**
- Perguntas vagas: "Como fazer data engineering?"
- Sem contexto: "Me d√° c√≥digo de Airflow" (qual DAG? qual objetivo?)
- Pedir tudo de uma vez: quebre em tarefas pequenas

### **üéØ ESTRUTURA IDEAL:**
1. Contexto (1 linha sobre o projeto)
2. Fase atual (onde est√° no roadmap)
3. Tarefa espec√≠fica (o que quer fazer agora)
4. O que j√° fez (evita repeti√ß√£o)
5. Onde travou (o problema exato)
6. D√∫vida clara (pergunta direta)
7. Formato desejado (c√≥digo/explica√ß√£o/ambos)

---

## üìå VOCABUL√ÅRIO DO PROJETO

Para contexto consistente, use esses termos:

- **Bronze layer:** Dados brutos (PostgreSQL ou GCS Parquet)
- **Silver layer:** M√©tricas intermedi√°rias (DBT)
- **Gold layer:** Features ML ou agrega√ß√µes finais (DBT)
- **DAG:** Workflow do Airflow
- **Expectation:** Valida√ß√£o do Great Expectations
- **Model:** Arquivo SQL do DBT (transforma√ß√£o)
- **Feature:** Coluna usada para treinar ML
- **Drift:** Mudan√ßa na distribui√ß√£o de dados (ML monitoring)

---

**Mantenha este template acess√≠vel durante todo o projeto!**
