"""
DAG: Bronze to Silver - Order Payments (Technical Transformations Only)
Fase 2 - Data Transformation - Silver Layer
Autor: Hyego
Data: 2025-01-29

RESPONSABILIDADE DESTA DAG:
- TransformaÃ§Ãµes TÃ‰CNICAS e NEUTRAS
- Limpeza, padronizaÃ§Ã£o, conversÃ£o de tipos
- SEM mÃ©tricas de negÃ³cio, KPIs ou agregaÃ§Ãµes

TransformaÃ§Ãµes aplicadas:
1. ConversÃ£o de tipos numÃ©ricos (payment_value)
2. PadronizaÃ§Ã£o de payment_type (lowercase, trim)
3. ValidaÃ§Ã£o de PK composta (order_id + payment_sequential)
4. Tratamento de valores nulos
5. Timestamps de auditoria
6. Ãndices para performance
"""

from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.providers.postgres.operators.postgres import PostgresOperator
from datetime import datetime, timedelta
import logging
import pandas as pd
from sqlalchemy import create_engine

default_args = {
    'owner': 'hyego',
    'depends_on_past': False,
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 2,
    'retry_delay': timedelta(minutes=5),
}

# ConfiguraÃ§Ãµes
DB_CONNECTION = "postgresql://airflow:airflow@postgres:5432/airflow"

# SQL para transformaÃ§Ã£o Bronze â†’ Silver (APENAS TÃ‰CNICO)
TRANSFORM_ORDER_PAYMENTS_SQL = """
-- ============================================
-- SILVER ORDER_PAYMENTS: TRANSFORMAÃ‡Ã•ES TÃ‰CNICAS
-- ============================================
-- Responsabilidade: Limpeza e padronizaÃ§Ã£o tÃ©cnica
-- SEM mÃ©tricas de negÃ³cio (anÃ¡lise de inadimplÃªncia, etc)
-- ============================================

DROP TABLE IF EXISTS olist_silver.order_payments;

CREATE TABLE olist_silver.order_payments AS
SELECT DISTINCT
    -- ============================================
    -- CHAVES (PK composta + FK)
    -- ============================================
    op.order_id,
    op.payment_sequential,
    
    -- ============================================
    -- TIPO DE PAGAMENTO (padronizado)
    -- lowercase + trim para consistÃªncia
    -- ============================================
    LOWER(TRIM(op.payment_type)) AS payment_type,
    
    -- ============================================
    -- PARCELAS (garantir tipo inteiro)
    -- ============================================
    op.payment_installments::INTEGER AS payment_installments,
    
    -- ============================================
    -- VALOR (NUMERIC para precisÃ£o financeira)
    -- ============================================
    op.payment_value::NUMERIC(10,2) AS payment_value,
    
    -- ============================================
    -- FLAGS TÃ‰CNICAS (derivadas, mas neutras)
    -- ============================================
    op.payment_value > 0 AS has_value,
    op.payment_installments > 1 AS is_installment,
    CASE 
        WHEN LOWER(TRIM(op.payment_type)) = 'credit_card' THEN TRUE
        ELSE FALSE
    END AS is_credit_card,
    CASE 
        WHEN LOWER(TRIM(op.payment_type)) = 'boleto' THEN TRUE
        ELSE FALSE
    END AS is_boleto,
    
    -- ============================================
    -- TIMESTAMPS DE AUDITORIA (tÃ©cnicos)
    -- ============================================
    CURRENT_TIMESTAMP AS processed_at,
    CURRENT_TIMESTAMP AS updated_at,
    CURRENT_TIMESTAMP AS created_at

FROM olist_raw.order_payments op

-- ============================================
-- GARANTIR: 1 registro por (order_id, payment_sequential)
-- ============================================
ORDER BY op.order_id, op.payment_sequential;

-- ============================================
-- ÃNDICES TÃ‰CNICOS (para performance)
-- ============================================
-- PK composta
CREATE INDEX idx_silver_order_payments_pk ON olist_silver.order_payments(order_id, payment_sequential);

-- FK
CREATE INDEX idx_silver_order_payments_order_id ON olist_silver.order_payments(order_id);

-- Campos de anÃ¡lise
CREATE INDEX idx_silver_order_payments_type ON olist_silver.order_payments(payment_type);
CREATE INDEX idx_silver_order_payments_value ON olist_silver.order_payments(payment_value);
CREATE INDEX idx_silver_order_payments_installments ON olist_silver.order_payments(payment_installments);
CREATE INDEX idx_silver_order_payments_processed_at ON olist_silver.order_payments(processed_at);

-- ============================================
-- COMENTÃRIOS TÃ‰CNICOS (documentaÃ§Ã£o)
-- ============================================
COMMENT ON TABLE olist_silver.order_payments IS 
'Silver Layer - Order Payments: Dados limpos e padronizados. SEM mÃ©tricas de negÃ³cio.';

COMMENT ON COLUMN olist_silver.order_payments.order_id IS 
'Parte da PK composta (order_id + payment_sequential). FK para orders';

COMMENT ON COLUMN olist_silver.order_payments.payment_sequential IS 
'Parte da PK composta. Sequencial do pagamento (1, 2, 3... para pedidos com mÃºltiplas formas)';

COMMENT ON COLUMN olist_silver.order_payments.payment_type IS 
'Tipo de pagamento padronizado (lowercase, trim). Ex: credit_card, boleto, voucher, debit_card';

COMMENT ON COLUMN olist_silver.order_payments.payment_installments IS 
'NÃºmero de parcelas (INTEGER). 1 = Ã  vista, >1 = parcelado';

COMMENT ON COLUMN olist_silver.order_payments.payment_value IS 
'Valor do pagamento (NUMERIC para precisÃ£o financeira)';

COMMENT ON COLUMN olist_silver.order_payments.is_installment IS 
'Flag tÃ©cnica: TRUE se payment_installments > 1';

COMMENT ON COLUMN olist_silver.order_payments.is_credit_card IS 
'Flag tÃ©cnica: TRUE se payment_type = credit_card';

COMMENT ON COLUMN olist_silver.order_payments.is_boleto IS 
'Flag tÃ©cnica: TRUE se payment_type = boleto';
"""


def validate_silver_order_payments():
    """
    Valida transformaÃ§Ãµes TÃ‰CNICAS da tabela silver order_payments.
    
    ValidaÃ§Ãµes:
    1. Volumetria (comparar com Bronze)
    2. Integridade de PK composta
    3. PadronizaÃ§Ã£o de payment_type
    4. DistribuiÃ§Ã£o de tipos de pagamento
    5. Valores e parcelas
    """
    logger = logging.getLogger(__name__)
    
    try:
        logger.info("ğŸ” Iniciando validaÃ§Ã£o TÃ‰CNICA da Silver order_payments...")
        
        engine = create_engine(DB_CONNECTION)
        
        # ============================================
        # VALIDAÃ‡ÃƒO 1: VOLUMETRIA
        # ============================================
        validation_query = """
        WITH bronze_count AS (
            SELECT COUNT(*) AS total FROM olist_raw.order_payments
        ),
        silver_count AS (
            SELECT COUNT(*) AS total FROM olist_silver.order_payments
        )
        SELECT 
            b.total AS bronze_records,
            s.total AS silver_records,
            s.total * 100.0 / b.total AS completeness_pct,
            CASE 
                WHEN s.total = b.total THEN 'OK'
                WHEN s.total >= b.total * 0.99 THEN 'WARNING'
                ELSE 'ERROR'
            END AS volumetry_status
        FROM bronze_count b, silver_count s;
        """
        
        df_volumetry = pd.read_sql(validation_query, engine)
        vol = df_volumetry.iloc[0]
        
        logger.info(f"""
        ğŸ“Š VALIDAÃ‡ÃƒO 1: VOLUMETRIA
        - Bronze: {vol['bronze_records']:,} registros
        - Silver: {vol['silver_records']:,} registros
        - Completude: {vol['completeness_pct']:.2f}%
        - Status: {vol['volumetry_status']}
        """)
        
        assert vol['volumetry_status'] != 'ERROR', "âŒ Perda significativa de dados!"
        
        # ============================================
        # VALIDAÃ‡ÃƒO 2: INTEGRIDADE DE PK COMPOSTA
        # ============================================
        keys_query = """
        SELECT 
            COUNT(*) AS total_records,
            COUNT(DISTINCT (order_id, payment_sequential)) AS unique_pks,
            SUM(CASE WHEN order_id IS NULL THEN 1 ELSE 0 END) AS null_order_id,
            SUM(CASE WHEN payment_sequential IS NULL THEN 1 ELSE 0 END) AS null_sequential,
            CASE 
                WHEN COUNT(*) = COUNT(DISTINCT (order_id, payment_sequential)) THEN 'OK'
                ELSE 'ERROR'
            END AS pk_integrity
        FROM olist_silver.order_payments;
        """
        
        df_keys = pd.read_sql(keys_query, engine)
        keys = df_keys.iloc[0]
        
        logger.info(f"""
        ğŸ”‘ VALIDAÃ‡ÃƒO 2: INTEGRIDADE DE PK COMPOSTA
        - Total registros: {keys['total_records']:,}
        - PKs Ãºnicas (order_id, payment_sequential): {keys['unique_pks']:,}
        - Nulls em order_id: {keys['null_order_id']}
        - Nulls em payment_sequential: {keys['null_sequential']}
        - Status PK: {keys['pk_integrity']}
        """)
        
        assert keys['null_order_id'] == 0, "âŒ Existem nulls em order_id (PK)!"
        assert keys['null_sequential'] == 0, "âŒ Existem nulls em payment_sequential (PK)!"
        assert keys['pk_integrity'] == 'OK', "âŒ Existem duplicatas na PK composta!"
        
        # ============================================
        # VALIDAÃ‡ÃƒO 3: TIPOS DE PAGAMENTO
        # ============================================
        type_query = """
        SELECT 
            payment_type,
            COUNT(*) AS total,
            ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (), 2) AS percentage,
            ROUND(AVG(payment_value), 2) AS avg_value,
            ROUND(AVG(payment_installments), 2) AS avg_installments
        FROM olist_silver.order_payments
        GROUP BY payment_type
        ORDER BY total DESC;
        """
        
        df_type = pd.read_sql(type_query, engine)
        
        logger.info("""
        ğŸ’³ VALIDAÃ‡ÃƒO 3: DISTRIBUIÃ‡ÃƒO POR TIPO DE PAGAMENTO
        """)
        for _, row in df_type.iterrows():
            logger.info(f"   - {row['payment_type']}: {row['total']:,} ({row['percentage']}%) | Avg: R$ {row['avg_value']:.2f} | Parcelas: {row['avg_installments']:.1f}")
        
        # Verificar se types estÃ£o lowercase
        uppercase_types = df_type[df_type['payment_type'].str.isupper()]
        assert len(uppercase_types) == 0, "âŒ payment_type nÃ£o foi convertido para lowercase!"
        
        # ============================================
        # VALIDAÃ‡ÃƒO 4: VALORES E PARCELAS
        # ============================================
        value_query = """
        SELECT 
            COUNT(*) AS total,
            SUM(CASE WHEN has_value = TRUE THEN 1 ELSE 0 END) AS with_value,
            SUM(CASE WHEN is_installment = TRUE THEN 1 ELSE 0 END) AS installments,
            SUM(CASE WHEN is_credit_card = TRUE THEN 1 ELSE 0 END) AS credit_card,
            SUM(CASE WHEN is_boleto = TRUE THEN 1 ELSE 0 END) AS boleto,
            ROUND(AVG(payment_value), 2) AS avg_value,
            ROUND(MIN(payment_value), 2) AS min_value,
            ROUND(MAX(payment_value), 2) AS max_value,
            ROUND(AVG(payment_installments), 2) AS avg_installments,
            MAX(payment_installments) AS max_installments
        FROM olist_silver.order_payments;
        """
        
        df_value = pd.read_sql(value_query, engine)
        val = df_value.iloc[0]
        
        logger.info(f"""
        ğŸ’° VALIDAÃ‡ÃƒO 4: VALORES E PARCELAS
        - Total pagamentos: {val['total']:,}
        - Com valor > 0: {val['with_value']:,} ({val['with_value']*100/val['total']:.2f}%)
        - Parcelados: {val['installments']:,} ({val['installments']*100/val['total']:.2f}%)
        - CartÃ£o de crÃ©dito: {val['credit_card']:,} ({val['credit_card']*100/val['total']:.2f}%)
        - Boleto: {val['boleto']:,} ({val['boleto']*100/val['total']:.2f}%)
        - Valor mÃ©dio: R$ {val['avg_value']:.2f}
        - Valor (min/max): R$ {val['min_value']:.2f} / R$ {val['max_value']:.2f}
        - Parcelas mÃ©dias: {val['avg_installments']:.2f}
        - MÃ¡ximo de parcelas: {val['max_installments']}
        """)
        
        # ============================================
        # VALIDAÃ‡ÃƒO 5: PEDIDOS COM MÃšLTIPLOS PAGAMENTOS
        # ============================================
        multi_query = """
        SELECT 
            COUNT(DISTINCT order_id) AS total_orders,
            SUM(CASE WHEN payment_count > 1 THEN 1 ELSE 0 END) AS orders_multiple_payments,
            MAX(payment_count) AS max_payments_per_order
        FROM (
            SELECT 
                order_id,
                COUNT(*) AS payment_count
            FROM olist_silver.order_payments
            GROUP BY order_id
        ) sub;
        """
        
        df_multi = pd.read_sql(multi_query, engine)
        multi = df_multi.iloc[0]
        
        logger.info(f"""
        ğŸ”¢ VALIDAÃ‡ÃƒO 5: MÃšLTIPLOS PAGAMENTOS
        - Total de orders: {multi['total_orders']:,}
        - Orders com mÃºltiplos pagamentos: {multi['orders_multiple_payments']:,}
        - MÃ¡ximo de pagamentos por order: {multi['max_payments_per_order']}
        """)
        
        # ============================================
        # VALIDAÃ‡ÃƒO 6: ÃNDICES
        # ============================================
        index_query = """
        SELECT COUNT(*) AS total_indexes
        FROM pg_indexes
        WHERE schemaname = 'olist_silver' AND tablename = 'order_payments';
        """
        
        df_idx = pd.read_sql(index_query, engine)
        idx_count = df_idx.iloc[0]['total_indexes']
        
        logger.info(f"""
        ğŸ”§ VALIDAÃ‡ÃƒO 6: ÃNDICES TÃ‰CNICOS
        - Total de Ã­ndices criados: {idx_count}
        - Esperado: 6 Ã­ndices
        """)
        
        assert idx_count == 6, f"âŒ Esperado 6 Ã­ndices, encontrado {idx_count}!"
        
        # ============================================
        # RESUMO FINAL
        # ============================================
        logger.info(f"""
        âœ… VALIDAÃ‡ÃƒO TÃ‰CNICA CONCLUÃDA COM SUCESSO!
        
        ğŸ“Š Resumo:
        - Volumetria: âœ… {vol['completeness_pct']:.2f}% preservado
        - Integridade PK: âœ… PK composta sem duplicatas
        - PadronizaÃ§Ã£o: âœ… payment_type em lowercase
        - Valores: âœ… Valor mÃ©dio R$ {val['avg_value']:.2f}
        - Ãndices: âœ… {idx_count} criados
        
        ğŸ¯ Silver Layer pronta para Gold Layer!
        """)
        
        engine.dispose()
        
        return {
            'status': 'success',
            'bronze_records': int(vol['bronze_records']),
            'silver_records': int(vol['silver_records']),
            'completeness_pct': float(vol['completeness_pct']),
            'avg_value': float(val['avg_value'])
        }
        
    except Exception as e:
        logger.error(f"âŒ Erro na validaÃ§Ã£o: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        raise


# DefiniÃ§Ã£o da DAG
with DAG(
    dag_id='20_bronze_to_silver_order_payments',
    default_args=default_args,
    description='[SILVER] TransformaÃ§Ãµes tÃ©cnicas: order_payments (limpeza + padronizaÃ§Ã£o)',
    schedule_interval=None,  # ExecuÃ§Ã£o manual
    start_date=datetime(2025, 1, 29),
    catchup=False,
    tags=['fase-2', 'silver', 'technical-transformation', 'order-payments'],
) as dag:
    
    # Task 1: Transformar Bronze â†’ Silver (apenas tÃ©cnico)
    task_transform_to_silver = PostgresOperator(
        task_id='transform_to_silver',
        postgres_conn_id='postgres_default',
        sql=TRANSFORM_ORDER_PAYMENTS_SQL,
    )
    
    # Task 2: Validar transformaÃ§Ãµes tÃ©cnicas
    task_validate_silver = PythonOperator(
        task_id='validate_technical_transformations',
        python_callable=validate_silver_order_payments,
    )
    
    # Pipeline de execuÃ§Ã£o (simples e linear)
    task_transform_to_silver >> task_validate_silver
