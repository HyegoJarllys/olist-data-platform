# üó∫Ô∏è OLIST DATA PLATFORM - ROADMAP COMPLETO

**Dura√ß√£o Total:** 8 semanas | **Esfor√ßo:** 120-160 horas | **Complexidade:** Pleno

---

## üìä VIS√ÉO GERAL DO PROJETO

### **Objetivo**
Construir plataforma de dados end-to-end demonstrando pr√°ticas enterprise em engenharia de dados, analytics, MLOps e BI.

### **Entregas Finais**
- 8 DAGs Airflow produ√ß√£o
- 20+ modelos DBT (bronze/silver/gold)
- 15+ valida√ß√µes Great Expectations
- 1 modelo ML com MLflow
- 4 dashboards (Power BI + Metabase)
- IA analytics com Vertex AI Gemini
- Documenta√ß√£o completa (10+ p√°ginas)

### **Skills Demonstradas**
Data Engineering (40%) | Analytics Engineering (30%) | MLOps (15%) | BI (10%) | AI (5%)

---

## üìÖ CRONOGRAMA MACRO

| Fase | Dura√ß√£o | Entreg√°vel Principal |
|------|---------|---------------------|
| **Fase 0: Setup** | Semana 1 | Airflow rodando, primeiro DAG |
| **Fase 1: Ingest√£o** | Semanas 2-3 | Dados em PostgreSQL + GCS |
| **Fase 2: Qualidade** | Semana 4 | Great Expectations configurado |
| **Fase 3: DBT** | Semanas 5-6 | Modelagem medalha completa |
| **Fase 4: ML** | Semana 7 | Modelo em produ√ß√£o (MLflow) |
| **Fase 5: BI** | Semana 8 (D1-4) | 4 dashboards publicados |
| **Fase 6: IA** | Semana 8 (D5-6) | Diagn√≥stico inteligente |
| **Fase 7: Docs** | Semana 8 (D7) | Portfolio completo |

---

## üöÄ FASE 0: SETUP & FUNDA√á√ÉO

**Dura√ß√£o:** 1 semana | **Esfor√ßo:** 15-20h

### **Objetivos**
- Ambiente desenvolvimento configurado
- Airflow rodando localmente
- GCP setup completo
- Primeiro DAG funcionando

### **Tarefas por Dia**

#### **Dia 1: Reposit√≥rio e Estrutura (3h)**
- [ ] Criar reposit√≥rio GitHub
- [ ] Clonar localmente
- [ ] Criar estrutura de pastas (airflow, dbt, ml, src, docs, data)
- [ ] Criar `.gitignore`, `.env.example`, `README.md`
- [ ] Primeiro commit

**Comandos:**
```bash
mkdir -p airflow/{dags,plugins,config,logs,tests}
mkdir -p dbt/models/{bronze,silver,gold}
mkdir -p ml/{models,features,pipelines}
mkdir -p src/{data,utils,ai_analytics}
mkdir -p docs data/raw dashboards
git add .
git commit -m "feat: initial structure"
```

#### **Dia 2-3: Docker e Airflow (6h)**
- [ ] Instalar Docker Desktop
- [ ] Criar `docker-compose.yml` (Airflow + PostgreSQL)
- [ ] Criar `requirements.txt`
- [ ] Inicializar Airflow: `docker-compose up airflow-init`
- [ ] Subir containers: `docker-compose up -d`
- [ ] Acessar UI: http://localhost:8080 (admin/admin)
- [ ] Criar DAG teste `00_hello_world.py`

**Valida√ß√£o:**
- Airflow UI acess√≠vel
- PostgreSQL conectado
- DAG teste executado com sucesso

#### **Dia 4: Google Cloud Platform (3h)**
- [ ] Criar conta GCP (ativar free trial US$ 300)
- [ ] Criar projeto: `olist-data-platform`
- [ ] Ativar APIs: BigQuery, Cloud Storage, Vertex AI
- [ ] Criar bucket GCS: `gs://olist-data-lake-[nome]`
- [ ] Criar dataset BigQuery: `olist_analytics`
- [ ] Criar service account (roles: BigQuery Admin, Storage Admin, Vertex AI User)
- [ ] Baixar JSON key (salvar como `gcp-credentials.json`, n√£o versionar!)
- [ ] Atualizar `.env` com credenciais
- [ ] Testar conex√£o (script Python)

**Valida√ß√£o:**
- Bucket vis√≠vel no GCS console
- Dataset vis√≠vel no BigQuery
- Script Python conecta sem erro

#### **Dia 5: Dados Olist (2h)**
- [ ] Baixar dataset Kaggle: https://kaggle.com/datasets/olistbr/brazilian-ecommerce
- [ ] Extrair 9 CSVs para `data/raw/`
- [ ] Criar DAG `01_test_olist.py` (ler CSV com pandas)
- [ ] Executar DAG e verificar logs

**Valida√ß√£o:**
- 9 CSVs em `data/raw/`
- DAG l√™ CSV sem erro
- Logs mostram primeiras linhas

#### **Dia 6-7: Schema PostgreSQL (4h)**
- [ ] Criar arquivo `src/database/schema.sql`
- [ ] Copiar schema das 9 tabelas (seu trabalho anterior!)
- [ ] Criar DAG `02_setup_database.py` (executa SQL)
- [ ] Executar DAG para criar tabelas
- [ ] Validar no PostgreSQL (9 tabelas vazias criadas)

**Valida√ß√£o:**
```sql
SELECT table_name FROM information_schema.tables 
WHERE table_schema = 'public';
-- Deve retornar 9 tabelas
```

### **Entreg√°veis Fase 0**
- [x] Reposit√≥rio GitHub configurado
- [x] Airflow rodando (localhost:8080)
- [x] GCP configurado (bucket + dataset)
- [x] Dados Olist baixados (9 CSVs)
- [x] Schema PostgreSQL criado (9 tabelas)
- [x] 2-3 DAGs funcionando
- [x] README.md inicial
- [x] Documenta√ß√£o: `docs/PHASE_0_SETUP.md`

---

## üì¶ FASE 1: INGEST√ÉO DE DADOS

**Dura√ß√£o:** 2 semanas | **Esfor√ßo:** 25-30h

### **Objetivos**
- CSV ‚Üí PostgreSQL (9 tabelas populadas)
- CSV ‚Üí GCS (data lake bronze layer)
- Valida√ß√µes b√°sicas automatizadas

### **Semana 2: Ingest√£o Batch**

#### **Dia 8: DAG CSV ‚Üí PostgreSQL (4h)**
- [ ] Criar `airflow/dags/03_ingest_csv_to_postgres.py`
- [ ] Fun√ß√£o para ler CSV com pandas
- [ ] Fun√ß√£o para carregar em PostgreSQL (to_sql)
- [ ] Criar tasks para 9 tabelas (ordem: independentes primeiro)
- [ ] Definir depend√™ncias (FKs)
- [ ] Executar DAG
- [ ] Validar row counts

**L√≥gica de Depend√™ncias:**
```
customers, sellers, products, categories, geolocation (paralelo)
    ‚Üì
orders (depende de customers)
    ‚Üì
order_items (depende de orders, products, sellers)
order_payments (depende de orders)
order_reviews (depende de orders)
```

**Valida√ß√£o:**
- 99.441 linhas em `customers`
- 99.441 linhas em `orders`
- 112.650 linhas em `order_items`

#### **Dia 9-10: DAG CSV ‚Üí GCS (5h)**
- [ ] Criar `airflow/dags/04_ingest_csv_to_gcs.py`
- [ ] Fun√ß√£o para converter CSV ‚Üí Parquet
- [ ] Fun√ß√£o para upload no GCS
- [ ] Estrutura de pastas: `bronze/{table}/{date}.parquet`
- [ ] Executar para 7 tabelas principais
- [ ] Verificar no GCS console

**Valida√ß√£o:**
- 7 arquivos Parquet no bucket
- Path: `gs://bucket/bronze/customers/2025-01-27.parquet`

#### **Dia 11: DAG de Valida√ß√£o (3h)**
- [ ] Criar `airflow/dags/05_validate_ingestion.py`
- [ ] Validar row counts (esperado vs real)
- [ ] Validar integridade FK (0 √≥rf√£os)
- [ ] Validar schema (colunas esperadas existem)
- [ ] Executar e garantir 100% pass

**Queries de Valida√ß√£o:**
```sql
-- Row counts
SELECT COUNT(*) FROM customers; -- expect 99441

-- FK integrity
SELECT COUNT(*) FROM orders o
LEFT JOIN customers c ON o.customer_id = c.customer_id
WHERE c.customer_id IS NULL; -- expect 0
```

### **Semana 3: Data Quality Foundation**

#### **Dia 12-13: Great Expectations Setup (6h)**
- [ ] Instalar Great Expectations no Airflow
- [ ] Inicializar: `great_expectations init`
- [ ] Conectar ao PostgreSQL como datasource
- [ ] Criar expectation suite: `orders_suite`
  - [ ] `expect_column_values_to_not_be_null` (order_id)
  - [ ] `expect_column_values_to_be_unique` (order_id)
  - [ ] `expect_column_values_to_be_in_set` (order_status)
- [ ] Executar valida√ß√£o manual
- [ ] Gerar Data Docs

**Valida√ß√£o:**
- Data Docs acess√≠vel (HTML)
- Suite com 3+ expectations

#### **Dia 14: Integra√ß√£o Airflow + GE (4h)**
- [ ] Criar `airflow/dags/06_data_quality_checks.py`
- [ ] Task para executar checkpoint GE
- [ ] Parse resultados (success/fail)
- [ ] Se falhar ‚Üí enviar alerta (print por enquanto)
- [ ] Schedule: ap√≥s DAG ingest√£o

**Valida√ß√£o:**
- DAG executa GE checkpoint
- Results aparecem em Data Docs

### **Entreg√°veis Fase 1**
- [x] 550k+ registros em PostgreSQL (9 tabelas)
- [x] Dados no GCS (bronze layer, Parquet)
- [x] DAG ingest√£o PostgreSQL
- [x] DAG ingest√£o GCS
- [x] DAG valida√ß√£o autom√°tica
- [x] Great Expectations configurado (3+ suites)
- [x] Data Docs gerados
- [x] 100% integridade FK validada
- [x] Documenta√ß√£o: `docs/PHASE_1_INGESTION.md`

---

## üîç FASE 2: DATA QUALITY

**Dura√ß√£o:** 1 semana | **Esfor√ßo:** 15-18h

### **Objetivos**
- Expandir expectation suites (15+ expectations)
- Alertas autom√°ticos
- Monitoramento de schema drift
- Dashboards de qualidade

### **Tarefas**

#### **Dia 15-16: Expectations Avan√ßadas (6h)**
- [ ] Suite para cada tabela principal (customers, orders, products)
- [ ] Expectations por tipo:
  - [ ] Nulls: colunas cr√≠ticas n√£o podem ser NULL
  - [ ] Ranges: pre√ßos > 0, review_score entre 1-5
  - [ ] Sets: status em lista v√°lida
  - [ ] Uniqueness: PKs √∫nicas
  - [ ] Relationships: FKs v√°lidas
  - [ ] Distributions: percentis esperados
- [ ] Executar e ajustar thresholds

**Meta:** 15+ expectations no total

#### **Dia 17: Alertas Telegram (3h)**
- [ ] Criar bot Telegram (via BotFather)
- [ ] Adicionar token no `.env`
- [ ] Criar `src/utils/telegram_alerts.py`
- [ ] Fun√ß√£o: `send_alert(message)`
- [ ] Integrar no DAG de qualidade
- [ ] Testar com falha simulada

**Valida√ß√£o:**
- Recebe mensagem no Telegram quando expectation falha

#### **Dia 18: Schema Evolution Tracking (3h)**
- [ ] Criar tabela `schema_history` (PostgreSQL)
- [ ] DAG que captura schema atual
- [ ] Compara com vers√£o anterior
- [ ] Se mudan√ßa ‚Üí alerta + log
- [ ] Schedule di√°rio

**Valida√ß√£o:**
- Detecta quando coluna nova √© adicionada

#### **Dia 19: Dashboard de Qualidade (4h)**
- [ ] Criar `dashboards/streamlit/data_quality.py`
- [ ] Conectar no PostgreSQL
- [ ] M√©tricas:
  - [ ] % expectations passing
  - [ ] Hist√≥rico de falhas (√∫ltimos 30 dias)
  - [ ] Schema changes log
  - [ ] Row counts por tabela
- [ ] Executar: `streamlit run data_quality.py`

**Valida√ß√£o:**
- Dashboard acess√≠vel em localhost:8501

### **Entreg√°veis Fase 2**
- [x] 15+ Great Expectations configuradas
- [x] Alertas Telegram funcionando
- [x] Schema drift detection
- [x] Dashboard data quality (Streamlit)
- [x] Data Docs atualizado
- [x] Documenta√ß√£o: `docs/PHASE_2_QUALITY.md`

---

## üèóÔ∏è FASE 3: ANALYTICS ENGINEERING (DBT)

**Dura√ß√£o:** 2 semanas | **Esfor√ßo:** 30-35h

### **Objetivos**
- Modelagem medalha (bronze/silver/gold)
- 20+ modelos DBT
- M√©tricas de neg√≥cio calculadas
- Testes DBT automatizados
- Data lineage documentada

### **Semana 5: Bronze e Silver**

#### **Dia 20-21: DBT Setup (6h)**
- [ ] Instalar dbt-core e dbt-bigquery
- [ ] Inicializar projeto: `dbt init olist_dw`
- [ ] Configurar `profiles.yml` (conex√£o BigQuery)
- [ ] Criar `dbt_project.yml`
- [ ] Testar conex√£o: `dbt debug`
- [ ] Criar primeiro modelo: `models/bronze/stg_orders.sql`

**Modelo Bronze Exemplo:**
```sql
-- models/bronze/stg_orders.sql
SELECT
    order_id,
    customer_id,
    order_status,
    order_purchase_timestamp,
    order_delivered_customer_date,
    order_estimated_delivery_date,
    _airbyte_extracted_at as loaded_at
FROM {{ source('raw', 'orders') }}
```

#### **Dia 22-23: Modelos Silver (8h)**
- [ ] Criar `models/silver/schema.yml`
- [ ] Modelo: `int_order_metrics.sql`
  - [ ] Calcular SLA entrega (real vs estimado)
  - [ ] Flag de atraso (boolean)
  - [ ] Tempo de entrega (dias)
- [ ] Modelo: `int_customer_rfm.sql`
  - [ ] Rec√™ncia (dias desde √∫ltima compra)
  - [ ] Frequ√™ncia (total de pedidos)
  - [ ] Monetary (valor total gasto)
- [ ] Modelo: `int_product_performance.sql`
  - [ ] Vendas por categoria
  - [ ] Ticket m√©dio por produto
  - [ ] Review score m√©dio
- [ ] Executar: `dbt run --models silver`

#### **Dia 24: Testes DBT (3h)**
- [ ] Adicionar testes em `schema.yml`:
  - [ ] `unique` (order_id)
  - [ ] `not_null` (colunas cr√≠ticas)
  - [ ] `relationships` (FKs)
  - [ ] `accepted_values` (order_status)
- [ ] Executar: `dbt test`
- [ ] Garantir 100% pass

### **Semana 6: Gold e Docs**

#### **Dia 25-26: Modelos Gold (8h)**
- [ ] Modelo: `fct_sales.sql`
  - [ ] Fato de vendas agregado
  - [ ] JOIN com dimens√µes (produto, cliente, tempo)
  - [ ] M√©tricas: receita, quantidade, ticket m√©dio
- [ ] Modelo: `fct_logistics.sql`
  - [ ] Fato de entregas
  - [ ] SLA, atrasos, tempo m√©dio
  - [ ] Agregado por regi√£o/seller
- [ ] Modelo: `mart_executive_kpis.sql`
  - [ ] KPIs executivos di√°rios
  - [ ] Receita, pedidos, NPS, churn
- [ ] Executar: `dbt run --models gold`

#### **Dia 27: Features ML (Gold) (4h)**
- [ ] Modelo: `ml_delivery_features.sql`
  - [ ] Features para prever atraso
  - [ ] Dist√¢ncia (estimada), seller_rating, categoria
  - [ ] Hist√≥rico do cliente, m√©todo pagamento
  - [ ] Label: `delivery_delayed` (boolean)
- [ ] Materializa√ß√£o: `table` (para ML)
- [ ] Exportar para CSV (usar em treino)

#### **Dia 28: DBT Docs e Airflow (3h)**
- [ ] Gerar docs: `dbt docs generate`
- [ ] Servir docs: `dbt docs serve`
- [ ] Adicionar descri√ß√µes em `schema.yml`
- [ ] Criar DAG `07_dbt_run.py`
- [ ] Task: `dbt run --models silver`
- [ ] Task: `dbt run --models gold`
- [ ] Task: `dbt test`
- [ ] Schedule: ap√≥s data quality pass

### **Entreg√°veis Fase 3**
- [x] DBT configurado (BigQuery)
- [x] 20+ modelos (5 bronze, 8 silver, 7 gold)
- [x] Modelagem medalha completa
- [x] M√©tricas: SLA, RFM, NPS, Churn, Ticket M√©dio
- [x] Features ML (delivery_features)
- [x] 10+ testes DBT (100% pass)
- [x] DBT docs gerados (com lineage)
- [x] DAG Airflow para DBT
- [x] Documenta√ß√£o: `docs/PHASE_3_DBT.md`

---

## ü§ñ FASE 4: MACHINE LEARNING

**Dura√ß√£o:** 1 semana | **Esfor√ßo:** 20-25h

### **Objetivos**
- Modelo XGBoost (previs√£o atraso entrega)
- MLflow setup (tracking + registry)
- Re-treino automatizado
- Drift detection

### **Tarefas**

#### **Dia 29-30: Treino Baseline (8h)**
- [ ] Criar `ml/pipelines/train_delivery_model.py`
- [ ] Carregar features do BigQuery (gold layer)
- [ ] Split temporal: 70% treino, 15% val, 15% teste
- [ ] Treinar XGBoost baseline (params default)
- [ ] Calcular m√©tricas: AUC-ROC, precision, recall, F1
- [ ] Salvar modelo: `models/delivery_xgboost_v1.pkl`

**Valida√ß√£o:**
- AUC-ROC > 0.55 (melhor que acaso)

#### **Dia 31: MLflow Setup (4h)**
- [ ] Instalar MLflow
- [ ] Inicializar tracking server local
- [ ] Modificar script treino para logar:
  - [ ] Par√¢metros (learning_rate, max_depth)
  - [ ] M√©tricas (AUC, F1)
  - [ ] Modelo (artifact)
  - [ ] Feature importance (plot)
- [ ] Executar treino novamente
- [ ] Acessar UI: http://localhost:5000

**Valida√ß√£o:**
- Experimento aparece no MLflow UI

#### **Dia 32: Otimiza√ß√£o (6h)**
- [ ] Instalar Optuna
- [ ] Criar `ml/pipelines/optimize_model.py`
- [ ] Definir espa√ßo de busca (hiperpar√¢metros)
- [ ] Executar 50 trials
- [ ] Registrar melhor modelo no MLflow
- [ ] Promover para "Production" stage

**Valida√ß√£o:**
- AUC-ROC melhorou (baseline vs otimizado)

#### **Dia 33: Drift Detection (4h)**
- [ ] Criar `ml/monitoring/drift_detection.py`
- [ ] Calcular PSI (Population Stability Index)
- [ ] Comparar distribui√ß√£o treino vs produ√ß√£o
- [ ] Se PSI > 0.2 ‚Üí alerta
- [ ] Integrar no DAG Airflow

#### **Dia 34: DAG ML (3h)**
- [ ] Criar `airflow/dags/08_ml_pipeline.py`
- [ ] Task: Treinar modelo (semanal)
- [ ] Task: Validar m√©tricas
- [ ] Task: Se melhor ‚Üí registrar MLflow
- [ ] Task: Deploy em "Production"
- [ ] Task: Drift detection (di√°rio)

### **Entreg√°veis Fase 4**
- [x] Modelo XGBoost treinado (AUC > 0.60)
- [x] MLflow configurado (tracking + registry)
- [x] Modelo otimizado (Optuna)
- [x] Drift detection implementado
- [x] DAG ML completo
- [x] Feature importance analisada
- [x] Documenta√ß√£o: `docs/PHASE_4_ML.md`

---

## üìä FASE 5: BUSINESS INTELLIGENCE

**Dura√ß√£o:** 4 dias | **Esfor√ßo:** 12-15h

### **Objetivos**
- 4 dashboards (Power BI + Metabase)
- KPIs executivos
- M√©tricas operacionais
- Self-service analytics

### **Tarefas**

#### **Dia 35-36: Power BI (6h)**
- [ ] Instalar Power BI Desktop
- [ ] Conectar em PostgreSQL
- [ ] Dashboard 1: Executive
  - [ ] KPIs: Receita, Pedidos, Ticket M√©dio, NPS
  - [ ] Gr√°fico: Receita ao longo do tempo
  - [ ] Gr√°fico: Top 5 categorias
  - [ ] Filtros: Data, Regi√£o
- [ ] Dashboard 2: Log√≠stica
  - [ ] % SLA entrega
  - [ ] Tempo m√©dio entrega por regi√£o
  - [ ] Mapa de calor (geolocaliza√ß√£o)
  - [ ] Alertas: pedidos atrasados
- [ ] Dashboard 3: Customer Experience
  - [ ] Review score m√©dio
  - [ ] Distribui√ß√£o (1-5 estrelas)
  - [ ] Word cloud de coment√°rios
  - [ ] Churn rate
- [ ] Publicar arquivos `.pbix` em `dashboards/power_bi/`

#### **Dia 37: Metabase (3h)**
- [ ] Instalar Metabase (Docker)
- [ ] Conectar em PostgreSQL + BigQuery
- [ ] Dashboard 4: Data Quality
  - [ ] Great Expectations: pass rate
  - [ ] Pipeline health (DAGs success rate)
  - [ ] Schema changes log
  - [ ] Lineage visual
- [ ] Configurar self-service (users podem criar queries)

#### **Dia 38: Streamlit App (3h)**
- [ ] Criar `dashboards/streamlit/exploratory.py`
- [ ] An√°lise interativa:
  - [ ] Upload CSV para an√°lise ad-hoc
  - [ ] Filtros din√¢micos
  - [ ] Gr√°ficos com Plotly
- [ ] Executar: `streamlit run exploratory.py`

### **Entreg√°veis Fase 5**
- [x] 3 dashboards Power BI (.pbix)
- [x] 1 dashboard Metabase (data quality)
- [x] Streamlit app (an√°lise explorat√≥ria)
- [x] KPIs executivos calculados
- [x] Screenshots dos dashboards
- [x] Documenta√ß√£o: `docs/PHASE_5_DASHBOARDS.md`

---

## üß† FASE 6: AI-POWERED MONITORING

**Dura√ß√£o:** 2 dias | **Esfor√ßo:** 6-8h

### **Objetivos**
- Vertex AI Gemini integrado
- Diagn√≥stico autom√°tico de falhas
- Alertas inteligentes

### **Tarefas**

#### **Dia 39: Vertex AI Setup (3h)**
- [ ] Ativar Vertex AI API no GCP
- [ ] Criar `src/ai_analytics/gemini_client.py`
- [ ] Fun√ß√£o: `analyze_logs(dag_id, task_id, error_message)`
- [ ] Prompt estruturado:
```
Voc√™ √© especialista em Airflow.
DAG: {dag_id}
Task: {task_id}
Erro: {error_message}
Logs: {logs_ultimas_100_linhas}
Analise e retorne JSON:
{
  "causa_raiz": "...",
  "sugestao_correcao": "...",
  "severidade": "critical/high/medium/low"
}
```
- [ ] Testar com erro simulado

#### **Dia 40: Integra√ß√£o Airflow (3h)**
- [ ] Modificar DAGs para capturar falhas
- [ ] On failure callback: chamar Gemini
- [ ] Parse resposta JSON
- [ ] Enviar alerta Telegram com diagn√≥stico
- [ ] Criar ticket GitHub (opcional)

**Exemplo Alerta:**
```
‚ö†Ô∏è DAG `dbt_run` FAILED
Task: `dbt_silver_models`

ü§ñ Diagn√≥stico IA:
Erro de sintaxe SQL no modelo `int_order_metrics.sql`
Linha 15: coluna `oder_id` n√£o existe (typo: order_id)

üí° Corre√ß√£o sugerida:
Alterar `oder_id` ‚Üí `order_id` linha 15

üîó Logs: [link]
```

### **Entreg√°veis Fase 6**
- [x] Vertex AI Gemini configurado
- [x] Diagn√≥stico autom√°tico funcionando
- [x] Alertas Telegram com IA
- [x] 3+ tipos de erro testados
- [x] Documenta√ß√£o: `docs/PHASE_6_AI_ANALYTICS.md`

---

## üìö FASE 7: DOCUMENTA√á√ÉO & POLISH

**Dura√ß√£o:** 1 dia | **Esfor√ßo:** 8-10h

### **Objetivos**
- README profissional
- Documenta√ß√£o completa (7 fases)
- Diagramas de arquitetura
- V√≠deo demo
- LinkedIn post

### **Tarefas**

#### **Dia 41: Documenta√ß√£o (6h)**
- [ ] Atualizar `README.md` (3000+ palavras)
- [ ] Criar/revisar 7 arquivos `PHASE_*.md`
- [ ] Criar `docs/ARCHITECTURE.md`
- [ ] Diagramas (draw.io ou Excalidraw):
  - [ ] Arquitetura geral
  - [ ] Pipeline de dados
  - [ ] Fluxo MLOps
- [ ] Adicionar badges no README
- [ ] Screenshots de dashboards
- [ ] GIFs de execu√ß√µes Airflow

#### **Dia 41 (tarde): V√≠deo e LinkedIn (4h)**
- [ ] Gravar v√≠deo demo (5 minutos):
  - [ ] Mostrar Airflow UI
  - [ ] Executar DAG
  - [ ] Mostrar dashboard Power BI
  - [ ] Mostrar MLflow
  - [ ] Mostrar alerta Telegram
- [ ] Upload no YouTube (unlisted)
- [ ] Escrever LinkedIn post (3 vers√µes):
  - [ ] Vers√£o BI (foco dashboards)
  - [ ] Vers√£o Analytics Eng (foco DBT)
  - [ ] Vers√£o Data Platform (completo)
- [ ] Publicar e engajar

### **Entreg√°veis Fase 7**
- [x] README.md atualizado (profissional)
- [x] 7 arquivos PHASE_*.md completos
- [x] 3 diagramas de arquitetura
- [x] V√≠deo demo (5 min)
- [x] LinkedIn post publicado
- [x] Portfolio 100% completo

---

## ‚úÖ CRIT√âRIOS DE SUCESSO

### **T√©cnicos**
- [ ] 8 DAGs Airflow sem erros (7 dias uptime)
- [ ] 100% Great Expectations passing
- [ ] 20+ modelos DBT deployados
- [ ] AUC-ROC modelo ML > 0.60
- [ ] 4 dashboards publicados
- [ ] 0 secrets no Git

### **Documenta√ß√£o**
- [ ] README com 3000+ palavras
- [ ] 7 arquivos de fase (10+ p√°ginas total)
- [ ] 3 diagramas profissionais
- [ ] V√≠deo demo gravado

### **Carreira**
- [ ] GitHub: 50+ commits
- [ ] LinkedIn: post com 50+ rea√ß√µes
- [ ] Curr√≠culo: 3 vers√µes (BI, Analytics, Platform)
- [ ] Aplica√ß√µes: 10+ vagas

---

## üéØ M√âTRICAS FINAIS DO PROJETO

| M√©trica | Valor |
|---------|-------|
| **Total de Registros** | 550.118 |
| **Tabelas Relacionais** | 9 |
| **Airflow DAGs** | 8 |
| **DBT Models** | 20+ |
| **Great Expectations** | 15+ |
| **Dashboards** | 4 |
| **Modelos ML** | 1 |
| **Linhas de C√≥digo** | ~3.000 |
| **Commits Git** | 50+ |
| **P√°ginas Docs** | 10+ |

---

## üìñ RECURSOS DE APRENDIZADO

### **Durante o Projeto**
- Airflow Docs: https://airflow.apache.org/docs/
- DBT Learn: https://courses.getdbt.com/
- Great Expectations: https://docs.greatexpectations.io/
- MLflow Docs: https://mlflow.org/docs/

### **Comunidades**
- r/dataengineering (Reddit)
- DBT Slack Community
- Stack Overflow (tags: airflow, dbt, great-expectations)

---

## üÜò TROUBLESHOOTING R√ÅPIDO

**Airflow n√£o sobe:**
```bash
docker-compose down -v
docker-compose up airflow-init
docker-compose up -d
```

**DAG n√£o aparece:**
- Verificar sintaxe Python
- Checar logs: `docker-compose logs airflow-scheduler`
- Refresh: F5 no browser

**GCS upload falha:**
- Validar service account permissions
- Testar: `gsutil ls gs://seu-bucket`

**DBT connection error:**
- Validar `profiles.yml`
- Testar: `dbt debug`

---

**Status:** Ready to Execute  
**√öltima Atualiza√ß√£o:** Janeiro 2025  
**Vers√£o:** 1.0

ü§ñ PROMPT TEMPLATE PARA IAs
markdown# TEMPLATE DE PROMPT - ASSIST√äNCIA NO PROJETO OLIST DATA PLATFORM

## üìã CONTEXTO DO PROJETO

**Projeto:** Olist Data Platform  
**Objetivo:** Construir plataforma de dados end-to-end (engenharia de dados + analytics + MLOps + BI)  
**Stack:** Airflow, DBT, Great Expectations, MLflow, Power BI, Metabase, Vertex AI  
**Dataset:** Olist Brazilian E-commerce (Kaggle) - 9 tabelas, 550k registros  
**Dura√ß√£o:** 8 semanas | **Status Atual:** [PREENCHER FASE ATUAL]

---

## üéØ COMO USAR ESTE TEMPLATE

Copie o template abaixo e preencha as se√ß√µes marcadas com [PREENCHER].  
Cole no ChatGPT/Claude/Gemini para obter assist√™ncia contextual.

---

## üìù PROMPT TEMPLATE
```
Sou desenvolvedor trabalhando no projeto **Olist Data Platform**, uma plataforma de dados completa para e-commerce demonstrando pr√°ticas enterprise.

**CONTEXTO DO PROJETO:**
- Stack: Airflow (orquestra√ß√£o), DBT (transforma√ß√£o), PostgreSQL + BigQuery (storage), MLflow (ML), Power BI (BI)
- Dataset: Olist Brazilian E-commerce (9 tabelas relacionais, 550k registros)
- Ambiente: Docker (Airflow local), Google Cloud Platform (BigQuery, GCS, Vertex AI)
- Objetivo: Portfolio profissional para vagas de Data Engineer / Analytics Engineer

**FASE ATUAL:**
[PREENCHER: ex: "Fase 3 - Analytics Engineering com DBT, estou criando modelos silver layer"]

**TAREFA ESPEC√çFICA:**
[PREENCHER: ex: "Preciso criar modelo DBT que calcula SLA de entrega (data real vs estimada)"]

**O QUE J√Å FIZ:**
[PREENCHER: ex: "J√° tenho dados em PostgreSQL, schema com 9 tabelas, DBT configurado"]

**ONDE ESTOU TRAVADO:**
[PREENCHER: ex: "N√£o sei como fazer DATEDIFF no BigQuery SQL"]

**D√öVIDA/PEDIDO:**
[PREENCHER: ex: "Me ajude a escrever query SQL (BigQuery) para calcular SLA de entrega"]

**FORMATO DESEJADO DA RESPOSTA:**
[ESCOLHA UMA OU MAIS:]
- [ ] Explica√ß√£o conceitual (sem c√≥digo ainda)
- [ ] C√≥digo SQL comentado
- [ ] C√≥digo Python comentado
- [ ] Passo a passo (1, 2, 3...)
- [ ] Exemplos pr√°ticos
- [ ] Boas pr√°ticas da ind√∫stria
- [ ] Links para documenta√ß√£o oficial

**RESTRI√á√ïES:**
- Usar apenas ferramentas gratuitas/open source
- C√≥digo deve rodar no ambiente Docker/GCP free tier
- Seguir padr√µes do projeto (nomes de pastas, conven√ß√µes)

**INFORMA√á√ÉO ADICIONAL:**
[OPCIONAL: qualquer contexto extra relevante]
```

---

## üìö EXEMPLOS DE USO

### **Exemplo 1: Ajuda com DBT**
```
Sou desenvolvedor trabalhando no projeto Olist Data Platform.

**FASE ATUAL:** Fase 3 - DBT, criando modelos silver layer

**TAREFA:** Criar modelo `int_order_metrics.sql` que calcula m√©tricas de pedidos

**O QUE J√Å FIZ:**
- DBT configurado, conectado no BigQuery
- Modelo bronze `stg_orders` j√° existe
- Tabelas: orders (order_id, order_purchase_timestamp, order_delivered_customer_date, order_estimated_delivery_date)

**ONDE ESTOU TRAVADO:**
- Como calcular diferen√ßa de dias entre datas no BigQuery?
- Como criar flag booleana "atrasado" (delivered > estimated)?

**D√öVIDA:**
Me ajude a escrever modelo DBT que:
1. Calcula dias entre purchase e delivery
2. Calcula dias de atraso (0 se entregue no prazo)
3. Cria flag `is_delayed` (boolean)

**FORMATO:** C√≥digo SQL comentado (BigQuery syntax)
```

---

### **Exemplo 2: Ajuda com Airflow**
```
Projeto: Olist Data Platform

**FASE ATUAL:** Fase 1 - Ingest√£o de dados

**TAREFA:** Criar DAG Airflow para carregar CSVs no PostgreSQL

**O QUE J√Å FIZ:**
- Airflow rodando via Docker
- 9 CSVs em `data/raw/`
- PostgreSQL com schema criado (9 tabelas vazias)

**ONDE ESTOU TRAVADO:**
- Como definir ordem de execu√ß√£o? (tabelas t√™m Foreign Keys)
- Como passar path do CSV para fun√ß√£o Python?

**D√öVIDA:**
Me mostre estrutura de DAG com:
- Tasks din√¢micas (loop sobre lista de tabelas)
- Depend√™ncias corretas (FKs)
- Error handling b√°sico

**FORMATO:** C√≥digo Python comentado
```

---

### **Exemplo 3: Ajuda com ML**
```
Projeto: Olist Data Platform

**FASE ATUAL:** Fase 4 - Machine Learning

**TAREFA:** Treinar XGBoost para prever atraso de entrega

**O QUE J√Å FIZ:**
- Features prontas no BigQuery (tabela `ml_delivery_features`)
- Colunas: distancia_km, categoria_produto, metodo_pagamento, seller_rating, label (is_delayed boolean)

**ONDE ESTOU TRAVADO:**
- Como fazer split temporal (n√£o aleat√≥rio)?
- XGBoost aceita vari√°veis categ√≥ricas direto ou precisa encoding?

**D√öVIDA:**
Me mostre c√≥digo Python para:
1. Carregar dados do BigQuery
2. Split temporal (70/15/15 por data)
3. Treinar XGBoost (lidar com categ√≥ricas)
4. Calcular AUC-ROC

**FORMATO:** C√≥digo Python comentado + explica√ß√£o do split temporal
```

---

## üéì DICAS PARA PROMPTS EFICAZES

### **‚úÖ FA√áA:**
- Seja espec√≠fico sobre a fase/tarefa atual
- Mencione o que j√° funciona (para n√£o repetir)
- Indique formato desejado (c√≥digo, explica√ß√£o, passo a passo)
- Diga suas restri√ß√µes (ferramentas gratuitas, ambiente Docker)

### **‚ùå EVITE:**
- Perguntas vagas: "Como fazer data engineering?"
- Sem contexto: "Me d√° c√≥digo de Airflow" (qual DAG? qual objetivo?)
- Pedir tudo de uma vez: quebre em tarefas pequenas

### **üéØ ESTRUTURA IDEAL:**
1. Contexto (1 linha sobre o projeto)
2. Fase atual (onde est√° no roadmap)
3. Tarefa espec√≠fica (o que quer fazer agora)
4. O que j√° fez (evita repeti√ß√£o)
5. Onde travou (o problema exato)
6. D√∫vida clara (pergunta direta)
7. Formato desejado (c√≥digo/explica√ß√£o/ambos)

---

## üìå VOCABUL√ÅRIO DO PROJETO

Para contexto consistente, use esses termos:

- **Bronze layer:** Dados brutos (PostgreSQL ou GCS Parquet)
- **Silver layer:** M√©tricas intermedi√°rias (DBT)
- **Gold layer:** Features ML ou agrega√ß√µes finais (DBT)
- **DAG:** Workflow do Airflow
- **Expectation:** Valida√ß√£o do Great Expectations
- **Model:** Arquivo SQL do DBT (transforma√ß√£o)
- **Feature:** Coluna usada para treinar ML
- **Drift:** Mudan√ßa na distribui√ß√£o de dados (ML monitoring)

---

**Mantenha este template acess√≠vel durante todo o projeto!**
